{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d10dbfa",
   "metadata": {},
   "source": [
    "## 前後端小知識\n",
    "* JavaScript 主要有兩個功能：(1)產生網頁動畫效果，(2)跟外部伺服器要資料，再動態產生內容\n",
    "* JSON 是一種資訊交換語言，後端可以把資料庫整成線上 JSON 格式，提供給前端做進一步的使用。前端要將 JSON 載入頁面，就要透過 XMLHttpRequest API (稱為 XHR)。XHR 是極好用的 JavaScript 物件，可讓網路請求透過 JavaScript 來檢索伺幅器的資源(例如圖片、文字、JSON，甚至 HTML 片段)，這樣不需載入整個頁面，就能更新小部分的內容，可讓網頁反應速度更快\n",
    "* client side render 跟 server side render 最大的差別：\n",
    "    - 對於後者，當你想要訪問文章列表這個頁面的時候，瀏覽器會送 request 到 server，然後經過 controller 與 model，最後把資料帶給 view。view 再回傳一份完整的 HTML 檔案（這個動作就叫做 render），而瀏覽器拿到之後，只要顯示出來就好。\n",
    "    - 對於前者，是在執行期間「動態」去跟後端伺服器拿資料，再動態產生你看到的那些元素。而那些元素原本不存在 index.html 裡面，是我們後來自己用 jQuery append 上去的，所以檢視原始碼不會出現任何東西。\n",
    "* MongoDB 是用 Key-value 的方式來儲存資料，長的跟 JSON 沒兩樣。值得注意的是 MongoDB 用的是所謂 BSON 而不是 JSON，每筆資料的 key 和 value 都是區分大小寫的。BSON 是 Binary JSON 的縮寫，就是拿 JSON 下去擴充，所以可以塞 Binary data 等 JSON 不能塞的東西\n",
    "\n",
    "\n",
    "不同函式庫：\n",
    "* Requests 庫：適合小規模、數據量小、爬取速度不敏感，爬取網頁\n",
    "* Scrapy 庫：適合中規模、數據規模較大、爬取速度敏感，爬取系列網站\n",
    "* 定製開發：適合大規模、搜索引擎級別、爬取速度關鍵，爬取全網\n",
    "* API：有 Python API 的券商：[永豐](https://www.sinotrade.com.tw/ec/20191125/Main/index.aspx)、[元大](http://www.yuantafutures.com.tw/pages/static-pages/service_future/product1_7.aspx?Node=65af4d99-3e51-4d4d-8802-ad5d9178187e&Show=LIST)、[富果](https://developer.fugle.tw/realtime/document)\n",
    "需另外透過 com 串接的券商：[群益](https://www.capital.com.tw/Service2/download/api.asp)、[凱基](https://www.kgifutures.com.tw/content/order04.html)\n",
    "\n",
    "[requests 操作](https://www.youtube.com/watch?v=xJNyvI2E9Ec)\n",
    "[BeautifulSoup 操作](https://www.youtube.com/watch?v=KHU4mPLqskA)\n",
    "[股票消息面新聞擷取](https://www.youtube.com/watch?v=TesL4Xjl9R8)\n",
    "[股票籌碼面資料擷取](https://www.youtube.com/watch?v=SBej3hKHkX4)\n",
    "[股票基本面財報分析](https://www.youtube.com/watch?v=AMV8JqT6tuE)\n",
    "[期貨盤後資訊擷取](https://www.youtube.com/watch?v=ilY1Iox6koM)\n",
    "[其他範例](https://www.youtube.com/watch?v=7yBAp7IeE98)\n",
    "[StockAI 數據抓取](https://www.youtube.com/watch?v=ZFvIfE3456E)1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86588b",
   "metadata": {},
   "source": [
    "## 爬蟲SOP\n",
    "1. 真人實際操作網頁並了解頁面如何觸發產生內容\n",
    "2. 判斷資料與架構是否分離：\n",
    "    - 資料與架構一起：右鍵檢視網頁原始碼，如果資料在原始碼裡，說明資料與架構在同一個檔案。之後就直接用 BeautifulSoup 在 HTML 裡爬資料\n",
    "    - 資料與架構分離：右鍵檢視網頁原始碼，如果資料不在原始碼裡，說明是分離的；或者，往下拖發現網頁動態載入，說明也是分離的。之後在第 4 步可先篩選 XHR，從中找尋 json 的 API。或用關鍵詞搜索。\n",
    "3. 透過 Chrome 開發人員工具(快捷鍵 option + command + i)，側錄網路請求封包\n",
    "4. 分析封包找出資料連結與傳送參數：（1）從 Network 標籤頁找出正確連結：挑選網頁關鍵字，逐一清查 Doc、XHR、JS、 WS 標籤頁中的 Preview、Response 標籤頁內容是否出現該關鍵字，可用 Ctrl+F 搜尋關鍵字；（2）並觀察 Headers 裡面的 Request URL、Request Method、Request Headers、Parameters 傳送參數\n",
    "5. 連線測試：（1）簡易方式確認網站是否有反爬蟲機制：將 Request URL 以 Chrome 無痕視窗確認，確認網頁是否為空白、回首頁或回傳 404、403、503，以及 Get/Post 傳送方式；（2）使用網路封包發送工具 Postman 測試連結是否能取回資料：Request URL、Request Method、Request Headers、Body 等。「需要帳號密碼登陸」或「機器人驗證碼」或「未滿十八歲」的問題：先登入帳號密碼及驗證碼，然後找到 header 裡面的 cookie 等資料放入 headers 參數裡，只要瀏覽器可以看得到的內容技術上都可以爬\n",
    "6. 撰寫爬蟲程式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301158d0",
   "metadata": {},
   "source": [
    "## 呼叫方式\n",
    "- GET：取得傳回來的全部資料。GET 傳送的參數稱為 Query String，類似明信片\n",
    "- POST：新增資料，同時也取得返回結果。POST 傳送的參數稱為 Form Data，類似信封\n",
    "- PUT：更新資料，同時也取得返回結果\n",
    "- DELETE：刪除資料，同時也取得返回結果\n",
    "\n",
    "## 資料類型\n",
    "- HTML：一般網頁的格式。需使用 BeautifulSoup 解析\n",
    "- JSON：一種簡易的資料表示格式，是樹狀結構。很容易解析\n",
    "- XML：一種資料表示格式，樣子與網頁語法類似。需使用 BeautifulSoup 解析。現在網路傳輸的資料大多是 JSON 格式，比較少用 XML 了\n",
    "- CSV：一種資料表示格式，以逗點區隔資料類型，一列存取一筆資料。使用 Pandas 分析，很容易解析\n",
    "- Javascript：有時候資料不是直接以 json 格式傳輸，可能藏在 js 裡面，這時可以當成一般的文字處理進行解析\n",
    "- TEXT：沒有特別格式的文字資料，例如大公司會自訂資料格式\n",
    "- BINARY：圖片、影片或 pdf, excel, rar 檔案等。可以用 with open('xxx', 'wb') as f:f.write(res.content) 存檔\n",
    "\n",
    "## 網頁反制爬蟲類型\n",
    "* Content-Type：內容類型\n",
    "* User-Agent：身分證\n",
    "* Referer：血統\n",
    "* Cookie：號碼牌\n",
    "* Location：驗證資料換人處理\n",
    "* Authorization\n",
    "* 動態參數：虛擬繳費碼\n",
    "* JavaScript：加密、混淆與Base64編碼\n",
    "* 鎖 IP 限制連線次數\n",
    "* 驗證碼\n",
    "* 瀑布式網頁"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175cd2a8",
   "metadata": {},
   "source": [
    "## requests\n",
    "requests.request(method, url, \\*\\*kwargs)\n",
    "\n",
    "\\*\\*kwargs：控制訪問的參數，可選項，包括：\n",
    "* params：字典或字節序列，作為參數增加到 url 中\n",
    "* data：字典、字節序列或文件對象，作為 Requests 的內容\n",
    "* json：JSON 格式的數據，作為 Requests 的內容。如果與 data 同時使用，則以 data 的資料為主\n",
    "* headers：字典，HTTP 定製頭\n",
    "* cookies：字典或 CookieJar，Request 中的 cookie\n",
    "* auth：元組，支持 HTTP 認證功能\n",
    "* files：字典類型，傳輸文件\n",
    "* timeout：設定超時時間，單位為秒\n",
    "* proxies：字典類型，設定訪問代理伺服器，可以增加登陸認證\n",
    "* allow_redirects：True/False，默認為 True，重定向開關\n",
    "* stream：True/False，默認為 True，獲取內容立即下載開關\n",
    "* verify：True/False，默認為 True，認證 SSL 憑證開關。如果遇到 SSL 憑證過期，需要改為 False 關閉驗證才能抓取資料\n",
    "* cert：本地 SSL 證書路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec445ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78aadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://stock-ai.com'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fddf95",
   "metadata": {},
   "source": [
    "requests.get(url, stream=True, verify=False)\n",
    "\n",
    "- verify=False：忽略SSL驗證\n",
    "- stream=False：\n",
    "get請求會把所有的資料請求下來，一個視訊1個G的話，會把1G的視訊下載到記憶體裡面，然後再進一步操作。\n",
    "- stream=True：\n",
    "get請求會先建立連線，而不會把content內容或text內容下載到記憶體裡，等開始對content操作的時候，get請求這個時候才開始下載資料。通常還可以這樣分一段一段寫入，這樣就可以友好地下載大檔案了，對於下載較大的視訊尤其管用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e36683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = ''\n",
    "res = requests.get(url, stream=True)\n",
    "with open('filename', 'wb') as fp:\n",
    "    for item in res.iter_content(10240):\n",
    "\t    # 10240表示每次會寫入10240個位元組，即10KB\n",
    "        fp.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response 對象的屬性\n",
    "print(res.status_code) # 狀態碼，參考 https://developer.mozilla.org/zh-TW/docs/Web/HTTP/Status\n",
    "print(res.encoding)    # 如果發現亂碼，需要設定編碼\n",
    "print(res.apparent_encoding)\n",
    "print(res.text)        # 取得內容 (以純文字型態讀取，會自動做編碼的轉換)\n",
    "print(res.content)     # 取得內容 (原始型態，可讀取二進位資料)\n",
    "print(res.json())      # 如果確定回傳的格式是 json，可以直接使用 res.json() 取得\n",
    "print(res.headers)     # 列出 HTTP Response Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3684f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 帳號密碼登入\n",
    "url = 'http://teaching.bo-yuan.net/'\n",
    "params = {'ex': 'login'}\n",
    "data = {\n",
    "    'ex[class]': '632ec67d1f521',\n",
    "    'ex[username]': '03王珊珊',\n",
    "    'ex[password]': 'd21d9a'\n",
    "}\n",
    "headers = {\n",
    "    'Cookie': 'PHPSESSID=7i2qb0elvt28necul60045en79',\n",
    "    'Referer': 'http://teaching.bo-yuan.net/'\n",
    "}\n",
    "\n",
    "res = requests.post(url, params = params, data = data, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML 格式，前提：當網頁有 table，並且可以直接 get 獲取\n",
    "url = 'https://tw.stock.yahoo.com/q/q?s=2330'\n",
    "res = requests.get(url)\n",
    "df = pd.read_html(res.text)\n",
    "df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 格式\n",
    "url = 'https://production.api.coindesk.com/v2/price/values/BTC'\n",
    "res = requests.get(url, params = {'start_date': 2021-8-15T12:47, 'end_date': 2021-10-15T12:47})\n",
    "\n",
    "# 法一：\n",
    "jd = json.loads(res.text)\n",
    "df = pd.DataFrame(jd['data']['entries'])\n",
    "\n",
    "# 法二：\n",
    "jd = res.json()\n",
    "df = pd.DataFrame(jd['data']['entries'])     # 可以用 res.get('data').get('entries') 避免錯誤？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c57344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 格式\n",
    "from io import StringIO\n",
    "\n",
    "url = 'https://www.twse.com/fund/BFI82U?response=csv'\n",
    "res = requests.get(url)\n",
    "res.encoding = 'utf-8'               # 如果發現亂碼，需要設定編碼\n",
    "df = pd.read_csv(StringIO(res.text), header = [1])      # 如果想要直接解析字串，可以用 io.StringIO() 將字串轉成檔案串流\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3fb92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "晴時多雲\n"
     ]
    }
   ],
   "source": [
    "# Javascript 格式\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://www.cwb.gov.tw/Data/js/TableData_36hr_County_C.js'\n",
    "res = requests.get(url)\n",
    "res = res.text.split(\"'10018':\")[1].split(\",\\n    '10004':\")[0]     # 針對回應處理\n",
    "res = res.replace(\"\\'\", \"\\\"\")       # 把字串轉換成 json 字串(單引號改成雙引號)\n",
    "jd = json.loads(res)                # 使用 json 把長得像 List 的字串轉回 List\n",
    "print(jd[0]['Wx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26dce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY 格式，例如圖片\n",
    "import requests\n",
    "\n",
    "image_url = ''\n",
    "res = requests.get(image_url, stream = True)\n",
    "if res.status_code == 200:\n",
    "    with open('img1.jpg', 'wb') as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e84ef",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "快速解析網頁 HTML 或 XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(res.text, 'html.parser')   # 分析 HTML 用 html.parser，分析 XML 用 lxml\n",
    "tb = soup.select('table')[2]\n",
    "df = pd.read_html(tb.prettify(), encoding = 'utf-8')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進階用法範例\n",
    "url = \"https://www.cnyes.com/twstock/a_technical10.aspx\"\n",
    "res = requests.get(url)\n",
    "soup = bs(res.text, \"lxml\")\n",
    "payload = {\n",
    "    'ctl00$ContentPlaceHolder1$D3': '2020-04-29',\n",
    "    'ctl00$ContentPlaceHolder1$D1': 'TSE'\n",
    "}\n",
    "\n",
    "for ele in soup.select(\"input[type=hidden]\"):\n",
    "    if(ele['value'] != \"\"):\n",
    "        payload[ele['name']] = ele['value']\n",
    "\n",
    "res = requests.post(url, data = payload)\n",
    "soup = bs(res.text, \"lxml\")\n",
    "tb = soup.select(\"table\")[0]\n",
    "df = pd.read_html(tb.prettify(), encoding = 'utf8')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進階用法範例，搭配正則表達式\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re, sys, time\n",
    "\n",
    "stockid = 2330\n",
    "year = 111\n",
    "url = f\"https://mops.twse.com.tw/mops/web/ajax_t05st01?firstin=1&TYPEK=sii&co_id={stockid}&year={year}\"\n",
    "url2 = \"https://mops.twse.com.tw/mops/web/ajax_t05st01?firstin=1&step=2&\" \n",
    "\n",
    "res = requests.get(url)\n",
    "df0 = pd.read_html(res.text, header = 0)\n",
    "df = df0[1]\n",
    "df.drop(['Unnamed: 5'], axis = 1, inplace=True)\n",
    "    \n",
    "l = []\n",
    "soup = bs(res.text, \"lxml\")\n",
    "for ele in soup.select(\"input[type=button]\"):\n",
    "    params = re.findall(\"(\\w+).value='(\\w+)'\", ele['onclick'])\n",
    "    res = requests.get(url2, params = dict(params))\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    dec = soup.select(\"pre\")[0]\n",
    "    l.append(re.sub('\\s+', '', dec.text))\n",
    "    time.sleep(2)\n",
    "\n",
    "df[\"詳細資料\"] = pd.Series(l)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de9111",
   "metadata": {},
   "source": [
    "選擇器\n",
    "* Html語法：<標籤 屬性>內文</標記>\n",
    "* CSS語法：選擇器{屬性:值;屬性值:值;}  \n",
    "* ID選擇器：#\n",
    "* Class選擇器：.\n",
    "* 通用選擇器：標籤\n",
    "* 屬性選擇器：標籤[屬性] 或 標籤[屬性=值]，例如a[href] 或 input[type=button]\n",
    "* 子選擇器：E>F\n",
    "* 後代選擇器：E F\n",
    "* 同層相鄰選擇器：E+F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73299a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_sample = ''' \n",
    "<html> \n",
    "     <head>\n",
    "         <title>iInfo資訊交流</title>\n",
    "     </head>\n",
    "     <body> \n",
    "         <h1 id=\"title\">股票價格</h1>         \n",
    "         <h3 id=\"header\">台積電---即時價格</h3>\n",
    "         <table>\n",
    "             <tr>\n",
    "                 <th>股票代號</th>\n",
    "                 <th>名稱</th>\n",
    "                 <th>開盤價</th>\n",
    "                 <th>最高價</th>\n",
    "                 <th>最低價</th>\n",
    "                 <th>成交價</th>                   \n",
    "             </tr>\n",
    "             <tr>\n",
    "                 <td>2330</td>\n",
    "                 <td>台積電</td>\n",
    "                 <td>250.5</td>\n",
    "                 <td>250.5</td>\n",
    "                 <td>246</td>\n",
    "                 <td>246</td>\n",
    "             </tr>\n",
    "         </table>\n",
    "         <div id='muse33' class=\"content\">\n",
    "         <p>台積電是台灣第一大半導體公司</p>\n",
    "         </div>\n",
    "         <input type=\"hidden\" id=\"kk\" name=\"kk\" value=\"abcdefghijk1234567890\" />\n",
    "         <input onclick=\"document.t05st01_fm.seq_no.value='1';document.t05st01_fm.spoke_time.value='144433';document.t05st01_fm.spoke_date.value='20180103';document.t05st01_fm.co_id.value='3008';document.t05st01_fm.TYPEK.value='sii';\" type=\"button\" value=\"詳細資料\"/>\n",
    "         <a href=\"http://www.tsmc.com.tw/chinese/default.htm\" class=\"qq\">台積電官網</a>\n",
    "         <a href=\"https://tw.stock.yahoo.com/q/q?s=2330\" class=\"qq\">Yahoo股市--台積電</a>\n",
    "         <a href=\"https://goodinfo.tw/StockInfo/StockDetail.asp?STOCK_ID=2330\" class=\"pp\">Goodinfo--台積電</a>\n",
    "         <img src=\"https://example.com/media/photo1.jpg\" with=\"600\" heigh=\"400\" alt=\"第一張圖片\">\n",
    "         <img src=\"https://example.com/media/photo2.jpg\" with=\"600\" heigh=\"400\" alt=\"第二張圖片\">\n",
    "         <img src=\"https://example.com/media/photo3.png\" with=\"600\" heigh=\"400\" alt=\"第三張圖片\">\n",
    "     </body> \n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(html_sample, 'lxml')\n",
    "\n",
    "print('ID選擇器範例：' + soup.select('#title')[0].text)\n",
    "print('Class選擇器範例：' + soup.select('.content')[0].text.strip())\n",
    "print('通用選擇器範例：' + soup.select('h1')[0].text)\n",
    "print('屬性選擇器範例：' + soup.select('a[href]')[0]['href'])    # 可用 x.get('屬性名稱') 或 x['屬性名稱'] 取標籤屬性\n",
    "print('屬性選擇器範例：' + soup.select('input[type=button]')[0]['value'])\n",
    "print('子選擇器範例：' + soup.select('#muse33 > p')[0].text)\n",
    "print('後代選擇器範例：' + soup.select('#muse33 p')[0].text)\n",
    "print('同層相鄰選擇器範例：' + soup.select('input + a')[0].text)\n",
    "\n",
    "for a in soup.select('a'):\n",
    "    print(a.text, a['href'])\n",
    "\n",
    "tb = soup.select('table')[0]\n",
    "df = pd.read_html(tb.prettify(), encoding = 'utf8')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find(id = 'title').text.strip())\n",
    "print(soup.find(None, class_ = 'content').text.strip())\n",
    "print(soup.find('div', 'content').text.strip())         # 預設 class_ = 'content'\n",
    "print(soup.find('h1').text)\n",
    "print(soup.find('a', {'href': re.compile(r\"stock\", flags = re.I)})['href'])\n",
    "print(soup.find('input', {'type': 'button'})['value'])\n",
    "\n",
    "for a in soup.find_all('a', 'qq'):\n",
    "    print(a.text, a['href'])\n",
    "    \n",
    "tds = soup.find_all('td')\n",
    "for td in tds:\n",
    "    print(td.text)\n",
    "    \n",
    "imgs = soup.find_all('img', {'src': re.compile('.*?\\.jpg')})      # 搭配正則表達式\n",
    "for img in imgs:\n",
    "    print(img['alt'], img['src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0827e",
   "metadata": {},
   "source": [
    "## 爬蟲通用代碼框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e64bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_html_text(url):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return '產生異常'\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    url = 'https://www.opec.org/basket/basketDay.json'\n",
    "    print(get_html_text(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ecfc9",
   "metadata": {},
   "source": [
    "## 正則表達式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re, sys, time\n",
    "\n",
    "stockid = 2330\n",
    "year = 111\n",
    "url = f\"https://mops.twse.com.tw/mops/web/ajax_t05st01?firstin=1&TYPEK=sii&co_id={stockid}&year={year}\"\n",
    "url2 = \"https://mops.twse.com.tw/mops/web/ajax_t05st01?firstin=1&step=2&\" \n",
    "\n",
    "res = requests.get(url)\n",
    "df0 = pd.read_html(res.text, header = 0)\n",
    "df = df0[1]\n",
    "df.drop(['Unnamed: 5'], axis = 1, inplace=True)\n",
    "    \n",
    "l = []\n",
    "soup = bs(res.text, \"lxml\")\n",
    "for ele in soup.select(\"input[type=button]\"):\n",
    "    params = re.findall(\"(\\w+).value='(\\w+)'\", ele['onclick'])\n",
    "    res2 = requests.get(url2, params = dict(params))\n",
    "    soup2 = bs(res2.text, \"lxml\")\n",
    "    dec = soup2.select(\"pre\")[0]\n",
    "    l.append(re.sub('\\s+', '', dec.text))\n",
    "    time.sleep(2)\n",
    "\n",
    "df[\"詳細資料\"] = pd.Series(l)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a624da",
   "metadata": {},
   "source": [
    "## selenium\n",
    "1. 下載 [chromedriver](https://chromedriver.chromium.org/downloads)，並放到專案資料夾下面\n",
    "2. 安裝 selenium：pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from pytube import Playlist\n",
    "import time\n",
    "import os\n",
    "\n",
    "driver = Chrome('./chromedriver')\n",
    "driver.get('https://www.youtube.com/view_all_playlists')\n",
    "driver.find_element_by_id('indentifierID').send_key('lingchequ@gmail.com')\n",
    "driver.find_element_by_id('indentifierNext').click()\n",
    "time.sleep(1)\n",
    "driver.find_element_by_class_name('whsOnd').send_keys('xxxxxxxxxxx')\n",
    "driver.find.element_by_id('passwordNext').click()\n",
    "time.sleep(5)\n",
    "\n",
    "ps = driver.find_elements_by_class_name('vm-video-title-text')\n",
    "for p in ps:\n",
    "    category = p.text\n",
    "    url = p.get('href')\n",
    "    pl = Playlist(url, suppress_exception = True)\n",
    "    dirname = 'youtube/' + category + '/'\n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "    pl.download_all(dirname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
